

Ecologists have long recognized that data exhibit spatial patterns \citep{Watt:patt:1947}. These patterns were often expressed as spatial autocorrelation \citep{Soka:Oden:spat:1978}, which is the tendency for sites that are close together to have more similar values than sites that are farther from each other.  When spatial autocorrelation exists in data, ecologists often use spatial statistical models because the assumption of independent errors is violated, making many conventional statistical methods inappropriate \citep{Clif:Ord:spat:1981,Lege:spat:1993}.   Areal data are one type of spatial ecological data, which involve polygons or area-referenced data with measured values from the polygons (e.g., animal counts from game management areas). For these types of spatial data, spatial information is encoded using neighborhoods, which leads to spatial autoregressive models \citep{Lich:Simo:Shri:Fran:spat:2002}. The two most common spatial autoregressive models are the conditional autoregressive (CAR) and simultaneous autoregressive (SAR) models \citep{Hain:spat:1990,Cres:stat:1993}. Our objective is to review CAR and SAR models in a practical way, so that their potential may be more fully realized and used by ecologists, and we begin with an overview of their many uses.

We motivate the uses of spatial autoregressive models by considering typical (and not so typical, but useful) objectives for ecological studies: 1) model selection, 2) spatial regression, 3) estimation of autocorrelation, 4) estimation of other connectivity parameters, 5) spatial prediction, and 6) spatial smoothing (Table~\ref{Tab:ARobj}).  When residual spatial autocorrelation is found based on, for example, Moran's I \citep{Mora:inte:1948,Soka:Oden:spat:1978}, none of the objectives in Table~\ref{Tab:ARobj} could be accomplished rigorously without modeling spatial autocorrelation.  When data are collected on spatial areal \citep[also called lattice,][]{Cres:stat:1993} units, SAR and CAR models provide the most straighforward and well-studied approach for accomplishing any of these objectives.  We briefly motivate each objective in turn and provide examples of studies in which autoregressive models were used.

Model selection (objective 1) can reveal important relationships between the response (i.e., dependent variable) and predictor variables.  There are a plethora of model comparison methods, or multimodel inferences, based on Akaike Information Criteria \citep[AIC,][]{Akai:Info:1973}, Bayes Information Criteria \citep[BIC,][]{Schw:esti:1978}, etc., that are generally available \citep[e.g.,][]{Burn:Ande:mode:2002,Hoot:Hobb:guid:2015}.  CAR and SAR covariance matrices may be part of some or all models, and choosing a model, or comparing various CAR and SAR models, may be an important goal of the investigation. For example, \citet{Cass:Dini:Rang:Thia:spat:2007} compared classical regression models assuming independence with SAR models while simultaneously selecting covariates using AIC when studying metabolism in amphibians. \citet{Qui:Turn:impo:2015} used SAR models for random errors along with model averaging in a study of landscape heterogeneity. \citet{Togn:Kelt:anal:2004} compared CAR and SAR based on autocorrelation in residuals, choosing SAR for an analysis of factors affecting mammalian species richness in South America.  In recent theoretical developments, \citet{Song:DeOl:Baye:2012} provided details on comparing various CAR and SAR models using Bayes factors. \citet{Zhu:Huan:Reye:sele:2010} extended the least absolute shrinkage and selection operator \citep[LASSO, ][]{Tibs:regr:1996} using the least angle regression algorithm \citep[LARS, ][]{Efro:Hast:John:Tibs:leas:2004} to CAR and SAR models. 

Regression analysis (objective 2) focuses on understanding relationships between predictor and response variables.  \citet{Gard:Lawl:Ver:Mago:Kell:coar:2010} used a spatial CAR regression model to show that the probability of wolverine occupancy depended on predictors related to elevation and human influence in the plots. Returning to an example above, \citet{Cass:Dini:Rang:Thia:spat:2007} found that several environmental predictors, including temperature, net primary productivity, annual actual precipitation, etc., helped explain species richness of amphibians.  \citet{Agar:Sila:Gelf:Dewa:Mick:trop:2005} used a CAR model to study the effect of landscape variables, including road and population density, on deforestation.  Using a SAR model for the spread of invasive alien plant species, \citet{Dark:biog:2004} found relationships with elevation, road density, and native plant species richness. \citet{Beal:Lenn:Year:Brew:Elst:regr:2010} provided a review of spatial regression methods, including CAR and SAR.  In many of these models, the autoregressive component was a latent random effect in a generalized linear mixed model, (also viewed as a hierarchical model \citep{Cres:Cald:Clar:VerH:acco:2009} or a state-space model \citep{deVa:Hast:fitt:2002}), where the response variable was counts \citep{Clay:Kald:empi:1987}, binary \citep{Gard:Lawl:Ver:Mago:Kell:coar:2010}, or ordinal \citep{Agar:Sila:Gelf:Dewa:Mick:trop:2005}.  Later, we provide more discussion of CAR and SAR in hierarchical models.

Understanding the strength of autocorrelation in spatial data (objective 3) can reveal connectivity and interrelatedness of ecological systems.  \citet{Gard:Lawl:Ver:Mago:Kell:coar:2010} used a Bayesian CAR model to estimate the autocorrelation parameter $\rho$, with credible intervals to show uncertainty. \citet{Lich:Simo:Shri:Fran:spat:2002} also provided estimates of the CAR autocorrelation parameter for three different bird species, along with likelihood ratio tests against the null hypothesis that they were zero.  Similarly, but for SAR models, \citet{Bull:Burk:eval:2005} used likelihood ratio tests to show significant estimates of several thousand tree species/location combinations with both positive and negative autocorrelation parameters.

Objective 4, understanding covariate effects on autocorrelation, is almost never used in ecological models, or in other disciplines. Historically, the neighborhood structure that forms the covariance matrix in CAR and SAR models is considered a nuisance; that is, it is a requirement to acknowledge spatial autocorrelation to make valid inferences on the other objectives in this list. However, in principle, we can consider distance or neighborhood structure as a covariate, and so logically we can extend this to any measurement between pairs of variables (locations). The influence of covariates on autocorrelation is often of interest in ecological studies \citep{Hank:Hoot:circ:2013} and we provide an example of how graphical models (mathematical constructs of points, or ``nodes,'' connected by lines, or ``edges'') can be used to address the objective later. 

Prediction at unsampled locations (objective 5) is a common goal in spatial analyses.  An example of prediction using CAR models is given in both \citet{Mago:Ray:John:Valk:Daws:Bowm:mode:2007} and \citet{Gard:Lawl:Ver:Mago:Kell:coar:2010}, who modeled occupancy of wolverines from aerial surveys \citep[also see][]{John:Conn:Hoot:Ray:Pond:spat:2013}. There were three types of observations: 1) plots that were surveyed with observed animals, 2) plots that were surveyed with no animals, and 3) unsurveyed plots.  Predictions for unsurveyed plots provided probabilities of wolverine occurrence. \citet{Huan:Grac:Hu:Rowl:Meng:spat:2013} predicted N$_2$O in pastures with missing samples using CAR models, and \citet{Thog:Saue:Knut:hier:2004} used CAR models to predict Cerulean Warblers abundance in the midwest US. Despite these examples, and the fact that geostatistics and time series are largely focused on prediction (at unsampled locations) and forecasting (at unsampled times in the future), respectively, there are few examples of prediction using CAR and SAR models in ecology, or other disciplines.

To conceptualize smoothing (objective 6), imagine that disease rates in conservation districts are generally low, say less than 10\% based on thousands of samples, but spatially patterned with areas of lower and higher rates.  However, one conservation district has but a single sample that is positive for the disease.  It would be unrealistic to estimate the whole conservation district to have a 100\% disease rate based on that single sample. CAR and SAR model can be used to create rates that smooth over observed data by using values from nearby districts to provide better estimates. For examples, see \citet{Begu:Mart:Rue:Cumm:hier:2012} and \citet{Evan:Kirc:Eyle:Ryan:Walt:habi:2016}. Entire books have been written on the subject \citep[e.g.,][]{Elli:Wake:Best:Brig:2000,Pfei:Robi:Stev:Stev:Roge:spat:2008,Laws:stat:2013}, and spatial smoothing of diseases form the introductions to CAR and SAR models in many textbooks on spatial statistics \citep{Cres:stat:1993,Wall:Gotw:appl:2004, Scha:Gotw:stat:2005, Bane:Carl:Gelf:hier:2014}.  Smoothing generally occurs when there is complete sampling from all areal units, something ecologists rarely have, and so this objective is used relatively infrequently. However, increasingly advanced instruments \citep[e.g., LIDAR, ][]{Camp:Wynn:intr:2011} are yielding remotely sensed data with complete spatial coverage.  In addition, smoothing over measurement error is attractive for hierarchical \citep{Cres:Cald:Clar:VerH:acco:2009} and state-space \citep{deVa:Hast:fitt:2002} models.

Our review shows that CAR and SAR models are used for many types of ecological inference, yet some highly cited ecological papers have incorrectly compared CAR/SAR to geostatistical models, incorrectly formulated the CAR model, and have given incorrect relationships between CAR and SAR models (details are given in Appendix A). We emphasize that good statistical practice with CAR and SAR models depends on more and better information.  When ecological data are collected in spatial areal units, CAR and SAR models are often the most appropriate approach for accounting for spatial autocorrelation, and are thus essential tools for making valid inference on spatial data.   To understand them better, we first compare CAR and SAR to geostatistical models.

A common framework for statistical inference in Ecology is regression or, more generally, a generalized linear model (GLM), in which variation in the response variable is modeled as a function of predictor variables (or covariates).  A key assumption in these models is that each response variable is independent from all others, after accounting for the covariate effects.  When the response variables are collected in space, it is very common for the residuals resulting from a regression or GLM analysis to show spatial autocorrelation.  Such autocorrelation violates the independence assumption, and can make standard results, such as confidence or credible intervals, invalid \citep{Clif:Ord:spat:1981,Lege:spat:1993}. 

Instead of assuming independence, spatial statistical models directly account for spatial autocorrelation through modeling the covariance matrix $\boldsymbol\Sigma$ of the residuals as a function of the locations where the response variable, contained in the vector $\mathbf{y}$, were collected.  For example, when the observations are point-referenced (i.e., each $y$ was collected at a location with known GPS coordinates), geostatistical methods are often used \citep[e.g.,][]{Turn:ONei:Conl:Conl:Hump:patt:1991}.  In a geostatistical model, the covariance of two observations is modeled directly as a function of the distance between the spatial locations where the observations were collected.  For example, under the exponential covariance model, covariance decays exponentially with distance $d_{ij}$ between observations
which makes observations which occur close to each other in space highly correlated, while observations that occur very far from each other are nearly independent.  Extending a regression model to allow for spatial autocorrelation \citep[e.g.,][]{Ver:Cres:Fish:Case:unce:2001} keeps inference on regression parameters from being invalidated by residual autocorrelation.

Geostatistical models are typically only appropriate when observations are point referenced, but a wide range of ecological studies collect observations from areal regions such as quadrats or pre-specified spatial polygons.  In this setting, geostatistical models for spatial autocorrelation, such as the exponential model, are not appropriate without adjustment \citep[but see ][]{Gotw:Youn:comb:2002}.  Instead, the most common approach to modeling spatial autocorrelation when observations are associated with areal units is an \emph{autoregressive} spatial model, in which a network of connections between neighboring areal units is specified, and spatial dependence is specified through a model that conditions on observations at neighboring locations.  This conditional spatial dependence can be shown to define the \emph{inverse} of a covariance matrix (also known as the precision matrix, the term that we will use henceforth).  Inverting this precision matrix then results in a spatial covariance matrix $\boldsymbol\Sigma$ defined by the network structure of the neighbor relationships. We illustrate with a simple example next.   

To introduce autoregressive models, and illustrate how the network structure of an autoregressive model results in spatial autocorrelation, we consider a simple setup in which observations are collected at nine locations arranged in a 3 $\times$ 3 grid (Fig.~\ref{Fig-3x3Graph}).



In a geostatistical model where the observations were obtained at a point-referenced location, we could define spatial autocorrelation based on the distance between sites (Eq.~\ref{eq:expGeo}).  In an autoregressive model, spatial autocorrelation is defined by neighborhood (network) structure.  In Fig.~\ref{Fig-3x3Graph}, we have defined neighborhood structure based on nearest neighbors in each cardinal direction.  Neighbors are shown by the vertical and horizontal lines, so site 1 has two neighbors, labeled 2 and 4, etc.  We can capture these neighborhood relationships in a matrix, which will be then define first a spatial precision matrix, and then a spatial covariance matrix.  For Fig.~\ref{Fig-3x3Graph}, let

be the matrix that indicates neighbor relationships, where a one in the $j$th column for the $i$th row indicates that site $j$ is a neighbor of site $i$, otherwise the entry is zero. The rows and columns correspond to the numbered sites in Fig.~\ref{Fig-3x3Graph}.  Under a CAR model for spatial autocorrelation, which we explore in more detail in this manuscript, the spatial precision matrix $\boldsymbol\Sigma^{-1}$ is defined as $(\mathbf{I}-\rho\mathbf{W})$, where $\rho$ is an autocorrelation parameter and $\mathbf{I}$ is a diagonal matrix of all ones.  The resulting spatial covariance matrix $\boldsymbol\Sigma$, which describes spatial correlation based on the neighborhood structure in $\mathbf{W}$, is obtained by inverting the precision matrix
where in this example, $\rho=0.2$.  

We use this simple example to illustrate that 1) geostatistical models are defined by actual spatial distance, while CAR and SAR models are defined by neighborhoods, and 2) geostatistical models specify the covariance matrix $\bSigma$ directly, whereas CAR and SAR models specify the precision matrix.  We also note that it is not immediately obvious how the covariance matrix will behave based on our neighborhood definitions (because of the nonlinear nature of a matrix inverse).  For example, the variances on the diagonal of Eq.~\ref{eq:3x3Sigma} are not all equal. Notice the covariances for site 1 (the off-diagonal elements in the first row of $\bSigma$), showing that site 1 is most highly correlated with sites 2 and 4, but also nonzero correlation with non-neighbors. \citet{Wall:clos:2004} found some surprising and unusual behavior for CAR and SAR models.  Our goal is to demystify CAR and SAR models, and provide practical suggestions for use of these models in ecological analyses. 

CAR and SAR models are prevalent in the literature, and the six goals listed above show that these models are essential tools for the analysis of ecological data.  Our objectives are as follows: 1) to explain how these models are obtained, 2) provide insight and intuition on how they work, 3) to compare CAR and SAR models, and 4) provide practical guidelines for their use. We provide an example for further illustration of the objectives given in Table~\ref{Tab:ARobj}. We then discuss important topics that have received little attention so far.  For example, there is little guidance in the literature on handling isolated (unconnected) sites, or how to choose between a CAR model and a special case of the CAR model, the intrinsic autoregressive model (IAR).  We provide such guidance, and finish with five take-home messages that deserve more attention.
 
Spatial relationships for CAR and SAR models are based on a graphical model, or a network, where sites are called nodes (circles in Fig.~\ref{Fig-3x3Graph}) and connections are called edges (lines in Fig.~\ref{Fig-3x3Graph}), using terminology from graphical models \citep[e.g.,][]{Laur:grap:1996, Whit:grap:2009}. Edges can be defined in many ways, but a common approach is to create an edge between adjoining units in geographic space or any network space. Statistical models based on graphical spatial structure are sometimes known as Gaussian Markov random fields \citep[e.g.,][]{Rue:Held:Gaus:2005}.  For notation, let $Y_i$ be a random variable used to model observations at the $i$th node, where $i = 1, 2, \dots, N$, and all $Y_i$ are contained in the vector $\by$. Then consider the spatial regression framework, 
where the goal is to model a first-order mean structure that includes covariates (i.e., predictor variables, $\bX$, measured at the nodes) with regression coefficients $\bbeta$, as well as a latent spatial random error $\bz$, where $\bz \sim \textrm{N}(\bzero,\bSigma)$, and independent error $\bvarepsilon$, where $\bvarepsilon \sim \textrm{N}(\bzero,\sigma^2_\varepsilon \bI)$. Note that $\bz$ is not directly measured, and instead must be inferred using a statistical model. The spatial regression framework becomes a spatial autoregressive model when the covariance matrix, $\bSigma$, for $\bz$, takes one of two main forms: 1) the SAR model,
Here, spatial dependence between $Z_i$ and $Z_j$ is modeled by $\mathbf{B} = \{b_{ij}\}$ and $\mathbf{C} = \{c_{ij}\}$ for the SAR and CAR models, respectively, where $b_{ii} = 0$ and $c_{ii} = 0$ and $\bM = \{m_{ij}\}$ is a diagonal matrix (all off-diagonal elements are 0), where $m_{ii}$ is proportional to the conditional variance of $Z_i$ given all of its neighbors. The spatial dependence matrices are often developed as $\bB = \rho\bW$ and $\bC = \rho\bW$, where $\bW$ is a weights matrix and $\rho$ controls the strength of dependence.  For the example in Eq.~\ref{eq:3x3Sigma}, we used a CAR model (Eq.~\ref{eq:CARcov}) with $\bC = \rho\bW$, where $\bW$ was given in Eq.~\ref{eq:3x3W}, and $\sigma^2_Z =1$, $\bM = \bI$, and $\rho = 0.2$.

To help understand autoregressive models, consider partial correlation \citep[e.g.,][pg. 361]{Sned:Coch:stat:1980}, which is the idea of correlation between two variables after ``controlling,'' or holding fixed, the values for all others variables. If $\bSigma\upi = \bOmega = \{\omega_{i,j}\}$, then the partial correlation between random variables $Z_i$ and $Z_j$ is $-\omega_{ij}/\sqrt{\omega_{ii}\omega_{jj}}$ \citep[pg. 120]{Laur:grap:1996}, which, for normally distributed data, is equivalent to conditional dependence. For the example in Fig.~\ref{Fig-3x3Graph} and Eq.~\ref{eq:3x3W}, $\bSigma\upi = (\bI - 0.2\bW)$ and so the partial correlation between sites 1 and 2 is 0.2. Thus, we can see that the CAR model, in particular, allows the modeler to directly specify partial correlations (or covariances), rather than (auto)correlation directly. That is, we are in control of specifying the off-diagonal matrix values of $\bW$ in $\bSigma\upi = \sigma^2_Z\bM\upi(\bI-\rho\bW)$, and therefore we are specifying the partial correlations. The SAR model case is similar, though instead of directly specifying partial correlations, as is done with $(\bI - \bC)$ in the CAR model, the SAR specification involves modeling a square root, $(\bI - \bB)$, of the inverse covariance matrix. Contrast this with geostatistics, where we are in control of specifying $\bSigma$, and therefore we are directly specifying the (auto)correlations.  In both cases, we generally use a functional parameterization, rather than specify every matrix entry individually.  For CAR and SAR models, the algorithm is often based on neighbors (e.g., partial correlation exists between neighbors that share a boundary), and for geostatistics, the algorithm is based on distance (e.g., correlation depends on an exponential decay with distance). For CAR models, if $c_{ij} = 0$, they are partially uncorrelated; otherwise there is partial dependence. Note that diagonal elements $b_{ii}$ and $c_{ii}$ are always zero.  For $\bz$ (a SAR or CAR random variable) to have a proper statistical distribution, $\rho$ must lie in a range of values that allows $(\bI-\bB)$ to have an inverse and $(\bI - \bC)$ to have positive eigenvalues; that is, $\rho$ cannot be chosen arbitrarily, and its range depends on the weights in $\bW$ (later, we discuss elements of $\bW$ other than 0 and 1).

The statistical similarities among the SAR and CAR models are obvious; they both rely on a latent Gaussian specification, a weights matrix, and a correlation parameter. In that sense, both the SAR and CAR models can be implemented similarly. However, there are key differences between SAR and CAR models that are fundamentally important because they impact inference gained from these models. As such, we describe each model in more detail provide practical advice.

One approach for building the SAR model begins with the usual regression formulation described in Eq. \ref{eq:ArealFramework}. Instead of modeling the correlation of $\bz$ directly, an explicit autocorrelation structure is imposed,
where the spatial dependence matrix, $\bB=\rho\bW$, is relating $\bz$ to itself, and $\bnu \sim \textrm{N}(\bzero,\sigma^2_Z \bI)$. These models are generally attributed to \citet{Whit:stat:1954}. Solving for $\bz$, note that $(\bI - \bB)\upi$ must exist \citep{Cres:stat:1993, Wall:Gotw:appl:2004}, and then $\bz$ has zero mean and covariance matrix $\bSigma = \sigma^2_Z((\bI - \bB)(\bI - \bB\upp))\upi$. The spatial dependence in the SAR model comes from the matrix $\bB$ that causes the simultaneous autoregression of each random variable on its neighbors. When constructing $\bB = \rho\bW$, the weights matrix $\bW$ does not have to be symmetric because it does not appear directly in the inverse of the covariance matrix (i.e., precision matrix).  For the example in Eq.~\ref{eq:3x3W}, the covariance matrix is

using $\rho = 2$. Eq.~\ref{eq:3x3SAR} can be compared to Eq.~\ref{eq:3x3Sigma}. Note, however, there are constraints to allow $(\bI - \bB)(\bI - \bB\upp)$ to be an inverse covariance matrix that are best explored through the eigenvectors and eigenvalues of $\bW$.  If $\lambda_{[1]} < 0$ is the smallest eigenvalue, and $\lambda_{[N]} > 0$ is the largest eigenvalue of $\bW$, then $1/\lambda_{[1]} < \rho < 1/\lambda_{[N]}$ is sufficient for an inverse of $(\bI - \bB)$, although it is possible to have models that do not depend on the eigenvales of $\bW$.  For Eq.~\ref{eq:3x3W}, the minimum eigenvalue is \ensuremath{-2.828} and the maximum is 2.828, with no eigenvalues equal to zero, so Eq.~\ref{eq:3x3W} can be made into a proper covariance matrix and $\rho$ must be between $\pm$ 0.354. 

The model created by Eq.~\ref{eq:ArealFramework} and Eq.~\ref{eq:sareta} has been termed the ``spatial error'' model version of SAR models.  An alternative is to simultaneously autoregress the response variable and the errors, $\by= \rho\bW\by + \bX\bbeta + \bvarepsilon$ \citep{Anse:spat:1988}, yielding the ``SAR lag model'' \citep{Kiss:Carl:spat:2008}, 
which allows the matrix $\bW$ to smooth covariates in $\bX$ as well as creating autocorrelation in the error for $\by$ \citep[e.g.,][]{Hoot:Hank:John:Alld:reco:2013}. A final version is to simultaneously autoregress both response and a separate random effect $\bnu$ \citep[e.g., ``SAR mixed model''][]{Kiss:Carl:spat:2008}, 

%------------------------------------------------------------------------------
%                     CAR Models
%------------------------------------------------------------------------------


\subsection*{CAR Models}

The term ``conditional'' in the CAR model is used because each element of the random process is specified conditionally on the values of the neighboring nodes. The CAR model is typically specified as
where $\bz_{-i}$ is the vector of all $Z_j$ where $j \ne i$, $\bC =\rho\bW$ is the spatial dependence matrix with $c_{ij}$ as its $i,j$th element, $c_{ii} = 0$, and $\bM$ is zero except for diagonal elements $m_{ii}$. Note that $m_{ii}$ may depend on the values in the $i$th row of $\bC$. In this parameterization, the conditional mean of each $Z_i$ is weighted by values at neighboring nodes. The variance component, $m_{ii}$, is also conditional on the neighboring nodes and is thus nonstationary, varying with node $i$.  In contrast to SAR models, it is not obvious that Eq. \ref{eq:car2} can lead to a full joint distribution for all random variables; however, this was demonstrated by \citet{Besa:spat:1974} using Brook's lemma \citep{Broo:dist:1964} and the Hammersley-Clifford theorem \citep{Hamm:Clif:Mark:1971,Clif:Mark:1990}. For $\bz$ to have a proper statistical distribution, $(\bI-\bC)$ must have positive eigenvalues and $\bSigma = \sigma^2_n(\bI-\bC)\upi\bM$ must be symmetric, which requires that
For CAR models, $\bW$ and $\rho$ can be constrained in exactly the same way as for SAR models; if $1/\lambda_{[1]} < \rho < 1/\lambda_{[N]}$ for $\lambda_{[1]}$ the smallest, and $\lambda_{[N]}$ the largest eigenvalues of $\bW$, then $\bI - \rho\bW$ will have positive eigenvalues. 

A special case of the CAR model, called the intrinsic autoregressive model (IAR) \citep{Besa:Koop:cond:1995}, occurs when Eq. \ref{eq:car2} is parameterized as
where $\cN_i$ are all of the locations defined as neighbors of the $i$th location, $|\cN_i|$ is the number of neighbors of the $i$th location, and $\tau^2$ is a constant variance parameter.  In Eq. \ref{eq:IAR}, each random variable is the average of its neighbors, and the variance is proportional to the inverse of the number of neighbors.  Next, we discuss the creation of weights based on averages of neighboring values.

%------------------------------------------------------------------------------
%                    Row-standardization
%------------------------------------------------------------------------------

\subsection*{Row-standardization}

We begin a discussion of the weights matrix, $\bW$, which applies to both SAR and CAR models.  Consider the simplest case, where a one in $\bW$ indicates a connection (an edge) between sites $i$ and $j$ and a zero indicates no such connection, as in Eq.~\ref{eq:3x3W}.  For site $i$, let us suppose that there are $|\cN_i|$ neighbors, so there are $|\cN_i|$ ones in the $i$th row of $\bW$.  In terms of constructing random variables, this implies that $Z_i$ is the \textit{sum} of its neighbors, and summing increases variance.  Generally, if left uncorrected, it will not be possible to obtain a covariance matrix in this case. As an analog, consider the first-order autoregressive (AR1) model from time series, where $Z_{i+1} = \phi Z_i + \nu_i$, and $\nu_i$ is an independent random variable.  It is well-known that $\phi = 1$ is a random walk, and anything with $|\phi| \geq 1$ will not have a variance because the series ``explodes'' \citep[e.g.,][pg. 53]{Hami:time:1994}.  There is a similar phenomenon for SAR and CAR models. In our simple example, for the construction $\rho\bW$, the value  $\rho |\cN_i|$ effectively acts like $\phi$, and both should be less than 1 to yield a proper statistical model. For example, consider the case where all locations are on an evenly-spaced rectangular grid of infinite size where each node is connected to 4 neighbors, called a rook's neighborhood; one each up, down, left, and right (as in Fig.~\ref{Fig-3x3Graph}). It is well-known that spatial autoregressive models for this example must have $|\rho| < 1/4$ \citep[pg. 82]{Hain:spat:1990} (compare this to the finite grid in Fig.~\ref{Fig-3x3Graph}, which had $|\rho| <$ 0.354). More generally, $|\rho| < 1/n$ if all sites have exactly $n$ neighbors, $|\cN_i| = n$ for all sites, to keep variance under control. This leads to the idea of row-standardization.  

If we divide each row in $\bW$ by $w_{i,+} \equiv \sum_j w_{ij}$, then, again thinking in terms of constructing random variables, each $Z_i$ is the \textit{average} of its neighbors, which decreases variance. Row-standardization of Eq.~\ref{eq:3x3W} yields
which is an asymmetric matrix. For the CAR models, if $\bW_+$ is an asymmetric matrix with each row in $\bW$ divided by $w_{i,+}$, then $m_{ii} = \tau^2/w_{i,+}$ (the $i$th diagonal element of $\bM$) satisfies Eq. \ref{eq:CarSymmetry}. Note that an additional variance parameter for $m_{i,i}$ will not be identifiable from $\sigma_Z^2$ in Eq. \ref{eq:CARcov}, so the row-standardized CAR model can be written equivalently as,
\begin{equation}\label{eq:bWone}
  \bSigma = \sigma_Z^2(\bI - \rho\bW_+)\upi\bM_+= \sigma_Z^2(\textrm{diag}(\bW\bone) - \rho\bW)\upi,
\end{equation}
where $\bone$ is a vector of all ones and diag($\bv$) creates a matrix of all zeros except the vector $\bv$ is on the diagonal. For both CAR and SAR models, regardless of the number of neighbors, when using row standardization, it is sufficient for $|\rho| < 1$, which is very convenient. Row standardization simplifies the bounds of $\rho$ and makes optimization easier to implement.  

Moreover, consider again the case of an evenly-spaced rectangular grid of points, but this time of finite size, again using a rook's neighborhood.  Using row standardization, points in the interior of the rectangle are averaged over 4 neighbors, and they will have smaller variance than those at the perimeter, averaged over 3 neighbors, and the highest variance will be locations in the corners, averaged over 2 neighbors.  Hence, in general, variance increases toward the \textit{perimeter}.  Without row standardization, even when $\rho$ controls overall variance, locations in the \textit{middle}, summed over more neighbors, have higher variance than those at the perimeter.  Using the example in Eq.~\ref{eq:3x3W},
with $\rho = 0.8$. The variances are on the diagonal, and these should be compared to Eq.~\ref{eq:3x3Sigma}. For an error process in Eq. \ref{eq:ArealFramework}, higher variance near the perimeter makes more sense (as in many kriging error maps), and, with a more natural and consistent range of values for $\rho$, row-standardization is beneficial. 

Using row-standardization, and setting $\rho = 1$ in Eq. \ref{eq:car2} leads to the IAR model in Eq. \ref{eq:IAR}.  In our AR1 analogy, this is equivalent to $\phi = 1$.  In this case, $\bSigma^{-1}$ is singular (i.e., does not have an inverse), and $\bSigma$ does not exist. It can be verified that Eq.~\ref{eq:W9plus} has a zero eigenvalue. While this may seem undesirable, random walks and Brownian motion are stochastic processes without covariance matrices \citep{Codl:Plan:Benh:rand:2008}.  Considering how they are constructed, it helps to think of the variances and covariances being defined on the increments; the differences between adjacent variables.  For these increments, the variances and covariances are well-defined. The IAR distribution is improper, however it is similarly well-defined on spatial increments or contrasts. To make the IAR proper, an additional constraint can be included, $\sum_i Z_i=0$. In essence, this constraint allows all of the random effects to vary except one, which is subsequently used to ensure that the values sum to zero as a whole. Geometrically, the sum-to-zero constraint can be thought of as anchoring the process near zero for the purposes of random errors in a model. With such a constraint, the IAR model is appealing as an error process in Eq. \ref{eq:ArealFramework}, forming a flexible surface where there is no autocorrelation parameter $\rho$ to estimate.  The IAR model is called a first-order intrinsic Gaussian Markov random field \cite[][p. 93]{Rue:Held:Gaus:2005}; higher orders are possible but we do not discuss them here. 

There is little guidance in the literature on how to choose the neighborhood structure in autoregressive models.  One reason for this is that there is rarely a clear scientific understanding of the mechanism behind spatial autocorrelation; rather, in most ecological modeling, our scientific understanding of the system is used to model the mean structure, and modeling spatial autocorrelation is a secondary consideration.  The formulation in Eq.~\ref{eq:ArealFramework} suggests that the spatial random effect $\mathbf{z}$ can be thought of as a missing covariate that is spatially smooth, but there are other possibilities as well. \citet{Hank:mode:2017} shows that the long-time limiting distribution of a spatio-temporal random walk can result in a spatial random effect with SAR covariance, indicating that SAR models can be seen as the covariance that results when the spatio-temporal process being studied could be approximated by a random walk. This is an example of a SAR model arising from a mechanism that may match a scientific question.  

In the absence of a scientific motivation for spatial autocorrelation, one way to view autoregressive models is as a modeling choice required to satisfy the assumption of independence of $\mathbf{y}$ in  Eq.~\ref{eq:ArealFramework}, conditional on $\mathbf{X}$ and $\mathbf{z}$.  In a regression analysis, one might consider multiple transformations of a response variable to satisfy the assumption of normality of residuals.  These transformations are not, in general, motivated by scientific understanding, but rather by modeling expediency.  Similarly, in a spatial analysis, one might consider multiple autoregressive models, such as SAR and CAR models with different neighborhood structures.  A final model could be chosen based on AIC, DIC, or other similar criteria.  In this situation, there is little to be gained by trying to interpret the CAR or SAR model that best fits the data.  Rather, the researcher should focus interpretation on mean effects (objective 2) or prediction (objective 5), and recognize that choosing a good neighborhood structure can improve both of these objectives.

The neighborhood structure of a CAR or SAR model depends on the connected nodes in the network; these are almost always defined as the areal units on which one has observations.  This choice can have unintended consequences, as it implies that the process being studied only exists on the specified areal units.  This would be appropriate, for example, when one is modeling recruitment on a species with a known geographic extent, and when the data collection has encompassed the entire range of the species.  As noted above, autoregressive models that use row-standardization tend to have higher marginal variance at the perimeter of the network - this corresponds with the assumption that we are often less certain about the state of a system at its boundaries than we are in more central spatial locations.

This assumption makes little sense when the system being studied is known to extend beyond the spatial range of the study.  In this case, there is no obvious reason to assume that higher variance would occur at the perimeter of the study region.  Instead, it would be more appropriate to extend the range of the spatial random effect by creating a buffer region of areal units on the boundary of the study region  \citep[e.g.,][]{Lind:Rue:Lind:expl:2011}.  While these buffer areal units would not have observations associated with them, they would stabilize the marginal variance of the spatial random effect, and would be appropriate whenever the process under study is known to extend beyond the spatial domain of the data.    

So far, we have reviewed standard spatial autoregressive models. Now, we want to consider their more general formulation as graphical, or network models. In general, the autoregressive component is an ``error'' process, and not often of primary interest (compared to prediction or estimating fixed effects parameters, $\bbeta$).  However, for ecological networks, there is a great deal of interest in studying spatial connectivity, or equivalently spatial autocorrelation. We discuss other weighting schemes for autoregressive models that have been very rarely, or never, used, but would provide valid autocorrelation models for studying connectivity in ecology.  In particular, although the decomposition is not unique, we introduce weighting schemes for the $\bW$ matrix that can separate and clarify structural and functional components in network connectivity.  By structural, we mean correlation that is determined by physical proximity, such as geographic neighborhoods, a distance measure, etc.  By functional, we mean correlation that is affected by dispersal, landscape characteristics, and other covariates of interest, which we illustrate next.

Consider a spatial network of nodes and edges, with the response variable measured at nodes, putting us in the setting of SAR and CAR models.  Let $\be_{ij}$ be a characteristic of an edge. The structural aspects can be accommodated in the neighborhood structure -- the binary representation of connectivity contains the idea of neighborhood structure. Then edge weights, $w_{ij}$, between the $i$th and $j$th nodes could combine functional and structural connectivity if they are modeled as,

where $\btheta$ is a $p$-vector of parameters.  To clarify, consider the case where $\bx_i$ is a vector of $p$ habitat characteristics of the $i$th node, $\be_{i,j} = (\bx_i +\bx_j)/2$, and $f(\be_{ij},\btheta) = \exp(\be\upp_{ij}\btheta)$ \citep{Hank:Hoot:circ:2013}. This allows a model of the effect that habitat characteristics at the nodes has on connectivity. If $\theta_h < 0$, then an increase in the $h$th habitat characteristic results in a smaller edge weight and greater resistance to network connectivity. However, if $\theta_h > 0$, then an increase in the $h$th habitat characteristic results in a larger edge weight and less resistance to network connectivity. In this example, the mean of the habitat characteristics found at the two nodes, $(\bx_i +\bx_j)/2$, was used, but any other function of the two values could also be used (e.g., difference) if it makes ecological sense.  Alternatively, $f(\be_{ij},\btheta)$ could be something that is directly measured on edges, such as a sum of pixel weights in a shortest path between two nodes from a habitat map.   

For a matrix representation of Eq. \ref{eq:FuncConnWts}, let $\bF(\btheta)$ be a matrix of functional relationships for \textit{all} edges, let $\bB$ be a binary matrix indicating neighborhood structure, and $\bW = \bF(\btheta) \odot \bB$, where $\odot$ is the Hadamard (direct, or element by element) product. Then $\bF(\btheta) \odot \bB$ allows a decomposition for exploring structural and functional changes in connectivity by manipulating each separately. Of course, this must respect the restrictions described above for SAR and CAR models, and the parameters need to be estimated, which we discuss in the section on fitting methods.

With a better understanding of SAR and CAR models, we now compare them more closely and make practical recommendations for their use; see also \citet{Wall:clos:2004}. First, we generally do not recommend versions of the SAR model given by Eq. \ref{eq:SARlagResp} and Eq. \ref{eq:SARlagMix}.  It is difficult to understand how smoothing/lagging covariates and extra random effects contribute to model performance, nor to our understanding, and these models performed poorly in ecological tests \citep{Dorm:etal:meth:2007, Kiss:Carl:spat:2008}. Henceforth, we only discuss the error model defined by Eq. \ref{eq:sareta}. 

A SAR model can be written as a CAR model and vice versa, although almost all published accounts on their relationships are incomplete \citep{Ver:Hank:Hoot:2017}. \citet[pg. 408]{Cres:stat:1993} demonstrated how a SAR model with four neighbors (rook's neighbor) results in a CAR model that involves all eight neighbors (queen's neighbor) plus rook's move to the second neighbors. It is evident from Eq. \ref{eq:SARcov} that specifying first-order neighbors in $\bB$ will result in non-zero partial correlations between second-order neighbors because of the product $(\bI - \bB)(\bI - \bB)\upp$ in the precision matrix.  Hence, SAR models have a reputation as being less ``local'' than the CAR models.  In fact, using the same construction $\rho\bW$ for both SAR and CAR models, \citet{Wall:clos:2004} showed that correlation (in $\bSigma$, not partial correlation) increases more rapidly with $\rho$ in SAR models than CAR models, which is also apparent when comparing Eq. \ref{eq:3x3Sigma} to Eq. \ref{eq:3x3SAR}. 

Regarding restrictions on $\rho$, \citet{Wall:clos:2004} also showed strange behavior for negative values of $\rho$. In geostatistics, there are very few models that allow negative spatial autocorrelation, and, when they do, it cannot be strong. Thus, in most situations, $\rho$ may be constrained to be positive. The fact that $\bW$ in SAR models is not required to be symmetric may seem to be an advantage over CAR models.  However, we point out that this is illusory from a modeling standpoint, although it may help conceptually in formulating the models.  For an analogy, again consider the AR1 model from time series.  The model is specified as $Z_{i+1} = \phi Z_i + \nu_i$, so it seems like there is dependence only on previous times.  However, the correlation matrix is symmetric, and $\corr(Z_i, Z_{i + t}) = \corr(Z_i,Z_{i - t}) = \phi^t$.  Note also that this shows that specifying partial correlations as zero (or conditional independence), does not mean that marginal correlation is zero (i.e., $\corr(Z_i, Z_{i + t}) \neq 0$ for all $t$ lags).  The same is true for CAR and SAR models.  In fact, the situation is less clear than for the AR1 models, where $\corr(Z_i, Z_{i + t}) = \phi^t$ regardless of $i$.  For CAR and SAR models, two sites that have the same ``distance'' from each other will have different correlation, depending on whether they are near the center of the spatial network, or near the perimeter; that is, correlation is nonstationary, just like the variance when we described row-standardization.

We now focus on the use of CAR and SAR spatial models within a hierarchical model. To discuss these models more specifically and concretely, in the example and following discussion, consider the following hierarchical structure that forms a general framework for all that follows,

where $[\cdot]$ denotes a generic statistical distribution \citep{Gelf:Smit:samp:1990}, with the variable on the left of the bar and conditional variables or parameters on the right of the bar.  Here, let $\by$ contain random variables for the potentially observable data, which could be further partitioned into $\by = (\by_o\upp, \by_u\upp)\upp$, where $\by_o$ are observed and $\by_u$ are unobserved.  Then $[\by|g(\bmu), \bnu]$ is typically the data model, with a distribution such as Normal (continuous ecological data, such as plant biomass), Poisson (ecological count data, such as animal abundance), or Bernoulli (ecological binary data, such as occupancy), which depends on a mean $\bmu$ with link function $g$, and other parameters $\bnu$.  The mean $\bmu$ has the typical spatial-linear mixed-model form, with design matrix $\bX$ (containing covariates, or explanatory variables), regression parameters $\bbeta$, spatially autocorrelated errors $\bz$, and independent errors $\bvarepsilon$.  We let the random effects, $\bz$, be a zero-mean multivariate-normal distribution with covariance matrix $\bSigma$.  In a geostatistical spatial-linear model, we would model $\bSigma$ directly with covariance functions based on distance like the exponential, spherical, and Matern \citep{Chil:Delf:geos:1999}. The variance $\sigma^2$, of the independent component $\var(\bvarepsilon) = \sigma^2\bI$, is called the nugget effect.  However, in CAR and SAR models, and as described above, we model the precision matrix, $\bSigma\upi$.  We denote this as a matrix function, $\bF$, that depends on other information (e.g., a neighborhood matrix $\bN = \bB$ or $\bC$, a distance matrix $\bD$, and perhaps others). We isolate the parameter $\rho$ that controls the strength of autocorrelation, and there could be other parameters contained in $\btheta$, that form the functional relationships among $\bN, \bD, \ldots$, and $\bSigma\upi$. In a Bayesian analysis, we could add further priors, but here we provide just the essential model components that provide most inferences for ecological data.  The model component to be estimated or predicted from Eq. \ref{eq:HMsetup} is identified in Table~\ref{Tab:ARobj}.  Note that a joint distribution for all random quantities can be written as $[\by|g(\bmu),\bnu][\bz|\bSigma][\bvarepsilon|\sigma^2]$, but the only observable data are $\by$. The term likelihood is used when the joint distribution is considered a function of all unknowns, given the observed data, which we denote $L(\cdot|\by)$, and this often forms the basis for fitting models (discussed next) and model comparison (Table~\ref{Tab:ARobj}).

Maximum likelihood estimation is one of the most popular estimation methods \citep{Cres:stat:1993}, but it can be computationally expensive. Earlier, when computers were less powerful, methods were devised to trade efficiency (on things like bias and consistency) for speed, such as pseudolikelihood \citep{Besa:stat:1975} and coding \citep{Besa:spat:1974} for CAR models, among others \citep{Cres:stat:1993}.  Both CAR and SAR models are well-suited for maximum likelihood estimation \citep{Bane:Carl:Gelf:hier:2014}. For spatial models, the main computational burden in geostatistical models is inversion of the covariance matrix; for CAR and SAR models, the inverse of the covariance matrix is what we actually model, simplifying computations \citep{Paci:spat:2013}.  Thus, only the determinant of the covariance matrix needs computing, and fast methods are available \citep{ Pace:Barr:fast:1997, Pace:Barr:spar:1997}, while if matrices do need inverting, sparse matrix methods can be used \citep{Rue:Held:Gaus:2005}. In addition, for Bayesian Markov chain Monte Carlo methods \citep[MCMC;][]{Gelf:Smit:samp:1990}, CAR models are ready-made for conditional sampling because of their conditional specification.

Spatial autoregressive models are often used in generalized linear models, which can be viewed as hierarchical models, where the spatial CAR model is generally latent in the mean function in a hierarchical modeling framework. Indeed, one of their most popular uses is for ``disease-mapping,'' whose name goes back to \citet{Clay:Kald:empi:1987}; see \citet{Laws:Baye:2009} for book-length treatment.  These models can be treated as hierarchical models \citep{Cres:Cald:Clar:VerH:acco:2009}, where the data are assumed to arise from a count distribution, such as Poisson, but then the log of the mean parameter has a CAR/SAR model to allow for extra-Poisson variation that is spatially patterned \citep[e.g.,][]{Ver:Jans:spac:2007}.  A similar hierarchical framework has been developed as a generalized linear model for occupancy, which is a binary model, but then the logit (or probit) of the mean parameter has a CAR/SAR model to allow for extra-binomial variation that is spatially patterned \citep{Mago:Ray:John:Valk:Daws:Bowm:mode:2007,Gard:Lawl:Ver:Mago:Kell:coar:2010,John:Conn:Hoot:Ray:Pond:spat:2013,Brom:John:Altw:Conq:spat:2014,Pole:Pond:Scha:Brow:Ray:John:occu:2014}.  CAR and SAR models can be embedded in more complicated hierarchical models as well \citep[e.g.,][]{Ver:Came:Bove:Lond:spat:2014}. Sometimes that may be too slow, and a fast general-purpose approach to fitting these types of hierarchical models, which depends in part on the sparsity of the CAR covariance matrix, is integrated nested Laplace approximation \citep[INLA,][]{Rue:Mart:Chop:appr:2009}. INLA has been used in generalized linear models for ecological data \citep[e.g.,][]{Haas:Hoot:Rizz:Meen:fore:2011,Aart:Fieb:Bras:Matt:quan:2013}, spatial point patterns \citep{Illi:Mart:Sorb:Gall:Zunz:Esqu:Trav:fitt:2013}, and animal movement models \citep{John:Hoot:Kuhn:esti:2013}, among others. The growing popularity of INLA is due in part to its fast computing for approximate Bayesian inference on the marginal distributions of latent variables.


We used trends in harbor seals (\emph{Phoca vitulina}) to illustrate the models and approaches for inference described in previous sections. The study area is shown in Fig.~\ref{Fig-Stocks} and contains 463 polygons used as survey sample units along the mainland, and around islands, in Southeast Alaska.  Based on genetic sampling, this area has been divided into 5 different ``stocks'' (or genetic populations). Over a 14-year period, at various intervals per polygon, seals were counted from aircraft.  Using those counts, a trend for each polygon was estimated using Poisson regression.  Any polygons with less than two surveys were eliminated, along with trends (linear on the log scale) that had estimated variances greater than 0.1.  This eliminated sites with small sample sizes.  We treated the estimated trends, on the log scale, as raw data, and ignored the estimated variances.  These data were chosen to be illustrative because we expected the trends to show geographic patterns (more so than abundance which varied widely in polygons) and stock structure connectivity, along with stock structure differences in mean values. The data were also continuous in value, thus we modeled the trends with normal distributions to keep the modeling simpler and the results more evident.  A map of the estimated trend values (that we henceforth treat as raw data) is given in Fig.~\ref{Fig-MapRaw}, showing 463 polygons, of which 306 had observed values and 157 were missing.

For neighborhood structures, we considered three levels of neighbors.  The first-order neighbors were based on any two polygons sharing one or more boundary point, and were computed using the \emph{poly2nb} function in the \emph{spdep} package \citep{Biva:Pira:comp:2015} in R \citep{R:Deve:Core:ALan:2016}. Some polygons were isolated, so they were manually connected to the nearest polygon in space using straight-line (Euclidean) distance between polygon centroids.  The first-order neighbors are shown graphically in Fig.~\ref{Fig-Neighbors}a with a close-up of part of the study area given in Fig.~\ref{Fig-Neighbors}b.  Let $\bN_1$ be a matrix of binary values, where a 1 indicates two sites are first-order neighbors, and a 0 otherwise. Then second-order neighbors, which include neighbors of first-order neighbors, were easily obtained in the matrix $\bN_2 = \cI(\bN^2)$. Here, $\cI(\cdot)$ is an indicator function on each element of the matrix, being 0 only when that element is 0, and 1 otherwise. A close-up of some of the second-order neighbors is shown in Fig.~\ref{Fig-Neighbors}c. The fourth-order neighbor matrix was obtained as $\bN_4 = \cI(\bN_2^2)$, and a close-up is shown in Fig.~\ref{Fig-Neighbors}d.

We considered covariance constructions that elaborated the three different neighborhood definitions.  Let $\bN_i; i = 1,2,4$ be a neighborhood matrix as described in the previous paragraph.  Let $\bS$ be a matrix of binary values that indicate whether two sites are in different stocks; that is, if site $i$ and $j$ are in the same stock, then $\bS[i,j] = 0$, otherwise $\bS[i,j] = 1$.  Finally, let the $i,j$th entries in $\bD$ be the Euclidean distance between the centroids of the $i$th and $j$th polygons.  Then the most elaborate CAR/SAR model we considered was
\begin{equation} \label{eq:CARex}
	\bW = \bN_i \odot \bF(\btheta) = \bN_i \odot \exp(-\bS/\theta_1) \odot \exp(-\bD/\theta_2).
\end{equation}
We use Eq. \ref{eq:CARex} in Eq. \ref{eq:SARcov} and Eq. \ref{eq:CARcov}, where for SAR models $\bB = \rho\bW$ or $\bB = \rho\bW_+$, and for CAR models $\bC = \rho\bW; \bM = \bI$ or $\bC = \rho\bW_+; \bM = \bM_+$. Note that, when considering the spatial regression model in Eq. \ref{eq:ArealFramework}, $\var(\by) = \bSigma + \sigma^2_\varepsilon\bI$ would also be possible; for example, for a first-order CAR model, $\var(\by) = \sigma_Z^2(\bI - \rho\bW)\upi + \sigma^2_\varepsilon\bI$.  However, when $\rho=0$, then $\sigma_Z^2$ and $\sigma^2_\varepsilon$ are not identifiable. In fact, as $\rho$ goes from 1 to 0, it allows for diagonal elements to dominate in $(\bI - \rho\bW)\upi$, and there seems little reason to add $\sigma^2_\varepsilon\bI$.  We evaluated some models with the additional component $\sigma^2_\varepsilon\bI$, but $\sigma^2_\varepsilon$ was always estimated to be near 0, so few of those models are presented.  The exception is the IAR model, where conceptually $\rho$ is fixed at one.

Our construction is unusual due to the $\exp(-\bS/\theta_1)$ component.  We interpret $\theta_1$ as an among-stock connectivity parameter.  Connectivity is of great interest to ecologists, and by its very definition it is about relationships \emph{between} two nodes.  Therefore, it is naturally modeled through the covariance matrix, which is also concerned with this \emph{second-order} model property.  Recall that, within stock, all entries in $\bS$ will be zero, and hence those same entries in $\exp(-\bS/\theta_1)$ will be one.  Now, if \emph{among} stocks there is little correlation, then $\theta_1$ should be very small, causing those entries in $\exp(-\bS/\theta_1)$ to be near zero.  On the  other hand, if $\theta_1$ is very large, then there will be high correlation among stocks, and thus the stocks are highly connected with respect to the behavior of the response variable, justifying our interpretation of the parameter.  When used in conjunction with the neighborhood matrix, the $\exp(-\bS/\theta_1)$ component helps determine if there is additional correlation due to stock structure (low values of $\theta_1$, meaning low connectivity) or whether the neighborhood definitions are enough ($\theta_1$ very large, meaning high connectivity).

We fit model Eq. \ref{eq:ArealFramework} with a variety of fixed effects and covariance structures, and a list of those models is given in Table~\ref{Tab:Models}.  We fit models using maximum likelihood (except for the IAR model, which does not have a likelihood, as discussed earlier), and details are given in Appendix B. The resulting maximized values of 2*log-likelihood are given in Fig.~\ref{Fig-ModelsM2LL}. Of course, some models are generalizations of other models, with more parameters, and will necessarily have a better fit.  Methods such as Akaike Information Criteria \citep[AIC,][]{Akai:Info:1973}, Bayesian Information Criteria \citep[BIC,][]{Schw:esti:1978}, or others \citep[see, e.g.,][]{Burn:Ande:mode:2002,Hoot:Hobb:guid:2015}, can be used to select among these models. This is an example of objective 1 listed in Table~\ref{Tab:ARobj}. For AIC, each additional parameter adds a ``penalty'' of 2 that is subtracted from the maximized 2*log-likelihood.  Fig.~\ref{Fig-ModelsM2LL} shows the number of model parameters along the x-axis, and dashed lines at increments of two help evaluate models. For example, XC4RD has 8 parameters, so, using AIC for model selection, it should be at least 2 better than a model with 7 parameters.  If one prefers a likelihood-ratio approach, then a model with one more parameter should be better by a $\chi$-squared value on 1 degree of freedom, or 3.841. We note that there appears to be high variability among model fits, depending on the neighborhood structure (Fig.~\ref{Fig-ModelsM2LL}).  Several authors have decried the general lack of exploration of the effects of neighborhood definition and choice in weights \citep{Best:Cock:Benn:Wake:Elli:ecol:2001,Earn:Morg:Meng:Ryan:Summ:Bear:eval:2007}, and our results support their contention that this deserves more attention.  In particular, it is interesting that row-standardized CAR models give substantially better fits than unstandardized, and CAR is much better than SAR. Also, for row-standardized CAR models, fit worsens going from first-order to second-order neighborhoods, but then improves when going to fourth-order.  Using distance between centroids had little effect until fourth-order neighborhoods were used.  By an AIC criteria, model XC4RD, with 8 parameters, would be the best model because it achieved an equal model fit as XC4RDS and XC4RDU with 9 parameters, but was also more than 2 better than any of the models with 7 parameters. For model XC4RDS, the parameter $\theta_1$ was very large, making $\exp(-\bS/\theta_1)$ nearly constant at 1, so this model component could be dropped without changing the likelihood.  Also, the addition of the uncorrelated random errors (model XC4RDU) had an estimated variance $\sigma_\varepsilon^2$ near zero, and left the likelihood essentially unchanged. 

As an example of objective 2 from Table~\ref{Tab:ARobj}, the estimation of fixed effects parameters, for 3 different models, are given in Table~\ref{Tab:Coeff}.  The model is overparameterized, so the parameter $\mu$ is essentially the estimate for stock 1. For example, for the XU model, $\exp($\ensuremath{-0.079}) = 0.92, giving an estimated trend of about 8\% average decrease per year for sites from stock 1. It is significantly different from 0, which is equivalent to no trend, at $\alpha$ = 0.05. This inference is obtained by taking the estimate and dividing by the standard error, and then assuming that ratio is a standard normal distribution under the null hypothesis that $\mu = 0$. The other estimates are \emph{deviations} from $\mu$, so stock 2 is estimated to have $\exp($\ensuremath{-0.079} + 0.048) = 0.97, or a decrease of about 3\% per year.  A $P$-value for stock 2 is obtained by assuming that the estimate divided by the standard error has a standard normal distribution under the model of no difference in means, which is 0.111, and is interpreted as the probability of obtaining the stock 2 value, or larger, if it had the same mean as stock 1.  It appears that stocks 3--5 have increasing trends, and that they are significantly different from stock 1 at $\alpha = 0.05$ when tested individually.  In comparison, model XC4R, using maximum likelihood estimates (MLE), and Bayesian estimates (MCMC), are given in the middle two sets of columns of Table~\ref{Tab:Coeff}.  Notice that, for both, the standard errors are larger than for the independence model XU, leading to greater uncertainty about the fixed effects estimates.  Also, the Bayesian posterior standard deviations are somewhat larger than those of maximum likelihood.  This is often observed in spatial models when using Bayesian methods, where the uncertainty in estimating the covariance parameters is expressed in the standard errors of the fixed effects, whereas for MLE the covariance parameters are fixed at their most likely values.  The MLE estimates and standard errors for the best-fitting model, according to AIC (model XC4RD), are shown in the last set of columns in Table~\ref{Tab:Coeff}, which are very similar to the XC4R model.  Further contrasts between trends in stocks are possible by using the variance-covariance matrix for the estimated fixed effects for MLE estimates, or finding the posterior distribution of the contrasts using MCMC sampling in a Bayesian approach.

For objective 3 from Table~\ref{Tab:ARobj}, consider the curves in Fig.~\ref{Fig-rhoProfile}.  We fit all combinations of CAR and SAR models, with and without row-standardization, for the first-, second-, and fourth-order neighbors (12 possible models).  All such models had 7 parameters, and a few of the models are listed in Table~\ref{Tab:Models}. The likelihood profiles for $\rho$ of the three best-fitting models are shown in Fig.~\ref{Fig-rhoProfile}. The peak value for XC4R shows that this is the best model, and the MLE for $\rho$ for this model is 0.604.  This curve also provides a likelihood-based confidence interval, known as a profile likelihood confidence interval \citep{Box:Cox:anal:1964}, which essentially inverts a likelihood-ratio test. A $100(1 - \alpha)$\% confidence interval for a given parameter is the set of all values such that a two-sided test of the null hypothesis that the parameter is the maximum likelihood value would not be rejected at the $\alpha$ level of significance (i.e., the MLE value minus a $\chi$-squared value with one degree of freedom, which is 3.841 if $\alpha = 0.05$).  These are all values above the dashed line in Fig.~\ref{Fig-rhoProfile} for model XC4R, or, in other words, the endpoints of the confidence interval are provided by the intersection of the dashed line with the curve, which has a lower bound of 0.113 and an upper bound of 0.868.  We also show the posterior distribution of $\rho$ for the same model, XC4R, using a Bayesian analysis.  The posterior mean was 0.687, with a 95\% credible interval ranging from 0.315 to 0.933.  The Bayesian estimate used improper uniform priors, so the joint posterior distribution of all parameters will be proportional to the likelihood.  The difference between the MLE and the Bayesian estimates for the XC4R model is due to the fact that the MLE is the peak of the likelihood jointly (with all other parameters at their peak), whereas the Bayesian posterior is a marginal distribution (all other parameters have essentially been integrated over by the MCMC algorithm).  Nonetheless, the MLE and Bayesian inferences are quite similar. 

Fig.~\ref{Fig-thetaProfiles} shows likelihood profiles for the other parameters in the covariance matrix.  For the best model, XC4RD, the solid line in Fig.~\ref{Fig-thetaProfiles}a shows a peak for $\log(\theta_2)$ at 3.717, forming the maximum likelihood estimate and relating to objective 4 from Table~\ref{Tab:ARobj}. Once again, we show a dashed line at the maximized 2*log-likelihood (413.447) minus a $\chi$-squared value at $\alpha = 0.05$ on one degree of freedom (3.841) to help visualize a confidence interval for $\theta_2$ (the profile likelihood confidence interval given by all values of the solid line that are above the dashed line). The log-likelihood drops rapidly from the MLE ($\hat{\theta}_2$ = 3.717) on the left, intersecting the dashed line and forming a lower bound at 2.894, whereas the upper limit is unbounded. We return to the notion of stock connectivity in Fig.~\ref{Fig-thetaProfiles}b.  The profile likelihood for $\theta_1$ for Model XC4RDS is given by the solid line. The likelihood is very flat for larger values of $\theta_1$, and in fact it is continuously increasing at an imperceptible rate. Thus, the MLE is the largest value in the parameter range, which we clipped at $\log(\theta_1) = 10$. A lower bound is at $\log(\theta_1)$ = 0.525, whereas the upper limit is unbounded again.

Continuing with further inferences from the model, we consider prediction (objective 5) from Table~\ref{Tab:ARobj}. Algorithms for both prediction and smoothing are given in Appendix C.  Kriging is a spatial prediction method associated with geostatistics \citep{Cres:orig:1990}.  However, for any covariance matrix, the prediction equations can be applied regardless of how that covariance matrix was developed.  We used universal kriging, that is, we included stock effects as covariates, \citep[][pg. 151]{Huij:Math:univ:1971,Cres:stat:1993} to predict all unsampled polygons (black polygons in Fig.~\ref{Fig-MapRaw}) using the XC4RD model. Note that kriging, as originally formulated, is an exact interpolator \citep[pg. 129]{Cres:stat:1993} that ``honors the data'' \citep[p. 252]{Scha:Gotw:stat:2005} by having predictions take on observed values at observed sites.  In Fig.~\ref{Fig-PredSmoo}a we show the raw observations along with the predictions, making a complete map for all sites. Of course, what distinguishes predictions using statistical models, as opposed to deterministic algorithms \citep[e.g., inverse distance weighted,][]{Shep:two:1968} is that statistical predictions provide uncertainty estimates for each prediction (Fig.~\ref{Fig-PredSmoo}B).  When kriging is used as an exact interpolator, the values are known at observed sites, so the prediction variances are zero at observed sites.  Hence, we only show the prediction standard errors for polygons with missing data.  

We also use the more traditional smoother for CAR and SAR models, such as those used in \citep{Clay:Kald:empi:1987}, forming objective 6 from Table~\ref{Tab:ARobj}.  For model XC4RD, without any independent component, this is essentially equivalent to leave-one-out-cross-validation. That is, the conditional expectation, which is obtained directly from Eq. \ref{eq:car2} (after adjusting for estimated covariate effects) is used rather than the observed value at each location. When the covariance matrix is known, for normally distributed data, ordinary kriging is also the conditional expectation \citep[p. 108, 174]{Cres:stat:1993}.  Hence, the predicted and smoothed values, using the conditional expectation, are given in Fig.~\ref{Fig-PredSmoo}c; note then, that the predictions are equivalent to Fig.~\ref{Fig-PredSmoo}a at the unsampled locations. Two extremes in smoothing approaches are 1) kriging as an exact predictor, that is, it leaves the data unchanged (Figs.~\ref{Fig-PredSmoo}a), and 2) removing observed data to replace them with conditional expectations based on neighbors (Fig.~\ref{Fig-PredSmoo}c).  In fact, both are quite unusual for a smoothing objective. Generally, a model is adopted with a spatial component, and a noisy measurement error or independent component.  Smoothing then involves finding a compromise between the spatial component and the raw, observed data. As an example for these data, consider the XI4RU model, which has an IAR component plus an uncorrelated error component.  The IAR model has very high autocorrelation ($\rho = 1$), but here we allowed it to be a mixture with uncorrelated error, and the relative values of $\sigma_Z^2$ and $\sigma^2_\varepsilon$ will determine how much autocorrelation is estimated for the data.  Under this model, predictions for observed data can fall between the very smooth IAR predictions and the very rough observed data. When such a model is formulated hierarchically (Eq. \ref{eq:HMsetup}), often in a Bayesian context, predictions exhibit a property called shrinkage \citep{Fay:Herr:esti:1979}, where predictions of observed values are some compromise between an ultra-smooth fit from a pure IAR model, and the roughness of the raw data (Fig.~\ref{Fig-PredSmoo}d).  The amount of shrinkage depends on the relative values of $\sigma_Z^2$ and $\sigma^2_\varepsilon$.  In fact, this is usually the case when CAR and SAR models are used in a generalized linear model setting because the conditional independence assumption (e.g., of a Poisson distribution) is analogous to the $\sigma^2_\varepsilon\bI$ component.  Note that a Bayesian perspective is not a requirement, a similar objective is obtained using filtered kriging \citep[][pg. 306]{Wall:Gotw:appl:2004} when there are both spatial and uncorrelated variance components.

Finally, to complete the example, we return to the idea of nonstationarity in variances and covariances.  Notice that, as claimed earlier, row-standardization causes variance to decrease with the numbers of neighbors (which are generally greater in the interior of a study area in contrast to the perimeter) for model XC4R (Fig.~\ref{Fig-MargVar}a), but it is not a simple function of neighbors alone, as it depends in complicated ways on the whole graphical (or network) structure.  In contrast, variance generally increases with the number of neighbors without row-standardization (model XC4) of the neighborhood matrix (Fig.~\ref{Fig-MargVar}a). Correlation also decreases with neighbor order, although not as dramatically as one might expect (Fig.~\ref{Fig-MargVar}b), and not at all (on average) between first-order to second-order when the neighborhood matrix is not row-standardized. Box plots summarize all possible correlations as a function of distance between centroids (binned into classes, Fig.~\ref{Fig-MargVar}c,d), which show that while correlation generally decreases with distance between centroids, there is a great deal of variation. Also recall that the MLE for $\rho$ for model XC4R was 0.604 (Fig.~\ref{Fig-rhoProfile}) for the inverse covariance matrix, but for the covariance matrix, correlations are much lower (Fig.~\ref{Fig-MargVar}b-d). Because weights are developed for partial correlations, or for the inverse of the covariance matrix, when we examine the covariance matrix itself, the diagonal elements are non-constant, in contrast to typical geostatistical models. It is important to realize that there is no direct calculation between the estimated $\rho$ value in the CAR or SAR model and the correlations in the covariance matrix; only that higher $\rho$ generally means higher correlations throughout the covariance matrix. One can always invert the fitted CAR or SAR model to obtain the full covariance matrix, and this can then be inspected and summarized if needed (e.g., Fig.~\ref{Fig-MargVar}), thus improving model diagnostics and our understanding of the fitted model.

Autoregressive models are an important class of spatial models that have rarely been explained in practical terms. We provide the following summary of CAR and SAR models.
\begin{enumerate}
 \item Intuition on CAR and SAR models can be obtained by considering the relationship between
autoregressive weights and partial correlations.
 \item Row standardization is generally a good idea after choosing initial neighborhoods and weights. This will result in CAR models that are generally more “local” for a given set of neighbors because, for that same set of neighbors, the SAR model squares the weights matrix, creating neighbors of neighbors in the precision matrix.
 \item The IAR model is a special case of the CAR model that uses row standardization and fixes the autocorrelation parameter at one, which leads to an improper covariance matrix; however, much like a similar AR1 model, or Brownian motion, these are still useful models.
\end{enumerate}

In addition, we presented six objectives, some of which are common, and others less so, in which spatial autoregressive models could be used. We fit a variety of CAR/SAR models using MLE and MCMC methods to an example data set to illustrate all six objectives outlined in the Introduction. In what follows, we provide further discussion on 5 take-home messages: 1) thoughts on choosing between CAR and IAR models, 2) modeling ecological effects in the covariance matrix, 3) the appeal of spatial smoothing, 4) how to handle isolated neighbors, and 5) software considerations.

The choice of IAR versus CAR is confusing, and while both are often described in the literature together, there is little guidance on choosing between them.  One advantage of the IAR is that it has one less parameter to estimate.  It was proposed by \citet{Besa:Koop:cond:1995} in part based on the following: they noticed that for a certain CAR model, $\rho$ in Eq. \ref{eq:CARcov} needed to be 0.999972 to have a marginal correlation near 0.75 (indeed, compare the estimate of $\hat{\rho}$ = 0.604 in our example yielding the correlations seen in Fig.~\ref{Fig-MargVar}). In many practical applications, $\rho$ was often estimated to be very near 1, so \citet{Besa:Koop:cond:1995} suggested the IAR model as a flexible spatial surface that has one less parameter to estimate.  On the other hand, critics noticed that it may force spatial smoothness where none exists \citep[e.g.,][]{Lero:Lei:Bres:esti:2000}. Our point of view is best explored through the hierarchical model Eq. \ref{eq:HMsetup}.  Consider an example of count data, where the data model, $\by \sim [\by|g(\bmu)]$, conditional on the mean $g(\bmu)$, is composed of independent Poisson distributions. Hence, there are no extra variance parameters $\bnu$, but rather the independent, nonstationary variance component is already determined because it is equal to the mean. In this case, we recommend the CAR model to allow flexibility in modeling the diagonal of the covariance matrix (the CAR model can allow for smaller $\rho$ values, which essentially allows for further uncorrelated error).  On the other hand, if $[\by|g(\bmu),\bnu]$ has a free variance parameter in $\bnu$ (e.g., the product of independent normal or negative binomial distributions), then we recommend the IAR model to decrease confounding between the diagonal of $\bSigma$, essentially controlled by $\rho$, and the free variance parameter in $\bnu$.

The results for Figs.~\ref{Fig-rhoProfile} and \ref{Fig-thetaProfiles} have confidence intervals that are quite wide.  In general, uncertainty is much higher when trying to estimate covariance parameters than regression (fixed effect) parameters. Nevertheless, the covariance models that we constructed demonstrate that it is possible to examine the effect of covariates in the covariance structure \citep[see also][]{Hank:Hoot:circ:2013}.  In other words, it is possible to make inference on connectivity parameters in the covariance matrix, but, secondly, they may be difficult to estimate with much precision if the data are measured only on the nodes.  In our harbor seal example, when stock effects were put into the mean structure, there was abundant evidence of different effects, but when that effect was put into the covariance matrix, the precision was quite low.  It is important to put connectivity effects into the covariance matrix (in many cases, that will be the only place that makes sense), but realize that they may be difficult to estimate well without large data sets.

From an ecological viewpoint, why do spatial smoothing?  Geostatistics had a tradition where modelers were often adamant that no smoothing occur \citep[``honoring the data,''][p. 224]{Scha:Gotw:stat:2005}. That tradition is often unknowingly continued with uncritical use of kriging formulas for prediction.  For example, if we assume that the observed values, without error, are part of the process of interest, then notice from Fig.~\ref{Fig-MapRaw} that the largest value is 0.835 from the legend on the right.  Recalling that these are trends, on the log scale, the observed value from the data was $\exp(0.835)=2.3$, or more than doubling each year.  That is clearly not a sustainable growth rate and is likely due to small sample sizes and random variation.  That same value from Fig.~\ref{Fig-PredSmoo}c is exp(0.039) = 1.04, or about 4\% growth per year, which is a much more reasonable estimate of growth.  The largest smoothed value in Fig.~\ref{Fig-PredSmoo}c, back on the exponential scale, was 1.083, or about 8\% growth per year, and the largest value in Fig.~\ref{Fig-PredSmoo}d, back on the exponential scale, was 1.146, or about 15\% growth per year. These values are similar to published estimates of harbor seal growth rates in natural populations \citep[e.g.,][]{Hast:Smal:Pend:sex:2012}.  Fig.~\ref{Fig-PredSmoo}c,d also clarifies the regional trends, which are difficult to see among the noise in Fig.~\ref{Fig-MapRaw} or by simply filling in the missing sites with predictions (Fig.~\ref{Fig-PredSmoo}a).  For these reasons, smoothing is very popular in disease-mapping applications, but it should be equally attractive for a wide variety of ecological applications. In particular, the XI4RU model (Fig.~\ref{Fig-PredSmoo}d) is appealing because it uses the data to determine the amount of smoothing.  However, we also note that when used in hierarchical models where, for the data model, the variance is fixed in relation to the mean (e.g., binomial, Bernoulli, and Poisson), the amount of smoothing will be dictated by the assumed variance of the data model.  In such cases, we reiterate the discussion on choosing between CAR and IAR.

A rarely discussed consideration is the case of isolated nodes (sites with no neighbors) when constructing the neighborhood matrix.  Having a row of zeros in $\bB$ in Eq. \ref{eq:SARcov}, or in $\bC$ in Eq. \ref{eq:CARcov}, will cause problems.  It is even easier to see that we cannot divide by zero in Eq. \ref{eq:IAR}, or during row-standardization.  Instead, we suggest that the covariance matrix be constructed as
where we show the data ordered such that all isolated sites are first, and their corresponding covariance matrix is $\sigma^2_I\bI$.  The matrix $\bSigma$ is the CAR or SAR covariance matrix for the sites connected by neighbors.  Note that one of the main issues here is the separation of the variance parameters, $\sigma^2_I$ and $\sigma^2_Z$ in Eq. \ref{eq:SARcov} or Eq. \ref{eq:CARcov}.  As seen in Eq. \ref{eq:IAR}, the autoregressive variance is often scaled by the number of neighbors, and because the isolated sites have no neighbors, it is prudent to give them their own variance parameter. 

Our final take-home message concerns software. Does the software check the weights to ensure the covariance matrix will be proper?  It may be computationally expensive to check it internally, which lessens the appeal of the autoregressive models, and the software may trust the user to give it a valid weights matrix. Does the software use row-standardization internally?  How does the software handle isolated sites?  These are special issues that only pertain to CAR and SAR models, so we suggest investigation of these issues so that the software output can be better understood.

In closing, we note that ``networks,'' and network models, are increasing throughout science, including ecology \citep{Borr:Mood:Edel:rise:2014}.  Looking again at Fig.~\ref{Fig-Neighbors}, if we remove the polygon boundaries, these are network models.  Spatial information, in the way of neighborhoods, was used to create the networks.  Thus, more general concepts for CAR and SAR models are the graphical models \citep{Laur:grap:1996, Whit:grap:2009}.  A better understanding of these models will lead to their application as network models when data are collected on the nodes of the network, and they can be extended beyond spatial data. This provides a rich area for further model development and research that can include, modify, and enhance the autoregressive models.



